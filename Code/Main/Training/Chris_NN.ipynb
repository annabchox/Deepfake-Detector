{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Foreword"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contains Chris's iterations of NN models. \n",
    "\n",
    "Outputs exported to `../Results/model_scores.csv`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rapid evolution of generative artificial intelligence (GPAI, LLMs) social media has rapidly increased the publicâ€™s access to powerful, deceptive tools. One such concern is the increasing prevalence of deepfake images, which pose a significant threat to public trust and undermines the epistemic integrity of visual media. (Source).\n",
    "\n",
    "These manipulated images can be utilized to spread false information, manipulate public opinion, and polarize communities, which can have serious consequences for both social and political discourse. In this project, we aim to develop a machine learning model that can detect differences between deepfakes and real images to combat the spread of manipulated visual media and protect the integrity of social discourse."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports, Global Variables, and Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from functools import partial\n",
    "import sys\n",
    "\n",
    "from tensorflow.keras.utils import set_random_seed\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization, Input, Rescaling\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import BinaryAccuracy, AUC, Precision, Recall, TrueNegatives, TruePositives, FalsePositives, FalseNegatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing global variables\n",
    "sys.path.append('../../Helper')\n",
    "import config\n",
    "\n",
    "# Setting random value\n",
    "set_random_seed(config.random_seed_value)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting w/h\n",
    "image_shape = img_to_array(load_img(\"../../../Data/Train/Real/real_1.jpg\")).shape\n",
    "w = image_shape[0]\n",
    "h = image_shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting filepaths to image data\n",
    "train_directory = \"../../../Data/Train\"\n",
    "validation_directory = \"../../../Data/Validation/\"\n",
    "test_directory = \"../../../Data/Test/\"\n",
    "directories = [train_directory, validation_directory, test_directory]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 140002 files belonging to 2 classes.\n",
      "Found 39428 files belonging to 2 classes.\n",
      "Found 10905 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Loading data\n",
    "mega_data = []\n",
    "for i in range(3):\n",
    "    mega_data.append(image_dataset_from_directory(\n",
    "        directory=directories[i],\n",
    "        image_size=(w, h),\n",
    "        batch_size=64,\n",
    "        seed=config.random_seed_value,\n",
    "        label_mode='binary'\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable names to data\n",
    "train_ds = mega_data[0]\n",
    "val_ds = mega_data[1]\n",
    "test_ds = mega_data[2]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model (Sequential)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing (Topology + Compiling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate\n",
    "model = Sequential()\n",
    "\n",
    "# input layer\n",
    "model.add(Input(shape=(w, h, 3)))\n",
    "model.add(Rescaling(1./255))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# convolutional layers\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Conv2D(32, (3,3), activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Conv2D(8, (3,3), activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "# hidden layers\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(8, activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# output layer\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "# compile\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.005),\n",
    "    loss=BinaryCrossentropy(),\n",
    "    metrics=config.standard_metrics\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2188/2188 [==============================] - 8408s 4s/step - loss: 0.4627 - binary_accuracy: 0.7749 - auc: 0.8582 - precision: 0.7561 - recall: 0.8115 - true_negatives: 51951.0000 - true_positives: 57086.0000 - false_positives: 18412.0000 - false_negatives: 13257.0000 - val_loss: 1.1873 - val_binary_accuracy: 0.7163 - val_auc: 0.7958 - val_precision: 0.6863 - val_recall: 0.8007 - val_true_negatives: 12398.0000 - val_true_positives: 15843.0000 - val_false_positives: 7243.0000 - val_false_negatives: 3944.0000 - lr: 0.0050\n",
      "Epoch 2/20\n",
      "1938/2188 [=========================>....] - ETA: 12:58 - loss: 0.3705 - binary_accuracy: 0.8314 - auc: 0.9133 - precision: 0.8162 - recall: 0.8555 - true_negatives: 50072.0000 - true_positives: 53052.0000 - false_positives: 11949.0000 - false_negatives: 8959.0000"
     ]
    }
   ],
   "source": [
    "# es = EarlyStopping(patience=3)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                              patience=5, min_lr=0.0005)\n",
    "res = model.fit(train_ds,\n",
    "                validation_data=val_ds, \n",
    "                epochs=20,\n",
    "                callbacks=[reduce_lr])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving results of model to csv\n",
    "# res.to_csv(\"../Results/model_scores.csv\", mode=\"a\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving image\n",
    "# plt.savefig(\"../../Images/_.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
